{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part g.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric \n",
        "!pip install pyg\n",
        "import os.path as osp\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GATConv\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAbBcYrnO1OH",
        "outputId": "68cf7e2f-9e57-49ee-f3be-f1730a8f5769"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.5.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: pyg in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: argh in /usr/local/lib/python3.7/dist-packages (from pyg) (0.26.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyg) (57.4.0)\n",
            "Requirement already satisfied: pkgtools>=0.7 in /usr/local/lib/python3.7/dist-packages (from pyg) (0.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_fiVfzXHN3Gb"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn.conv.gatv2_conv import GATv2Conv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cora Dataset\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora', transform=T.NormalizeFeatures())\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "pengUQESN-Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GATv2Conv(in_channels, 8, heads=8, dropout=0.6)\n",
        "        self.conv2 = GATv2Conv(8 * 8, out_channels, heads=1, concat=False,\n",
        "                             dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net(dataset.num_features, dataset.num_classes).to(device)\n",
        "data = data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "def train(data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    out, accs = model(data.x, data.edge_index), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        acc = float((out[mask].argmax(-1) == data.y[mask]).sum() / mask.sum())\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    train(data)\n",
        "    train_acc, val_acc, test_acc = test(data)\n",
        "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
        "          f'Test: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP6guvbSOA4V",
        "outputId": "5b5d45bd-adc8-4137-8537-d106c3d4e243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train: 0.1357, Val: 0.3140, Test: 0.3190\n",
            "Epoch: 002, Train: 0.1357, Val: 0.3160, Test: 0.3240\n",
            "Epoch: 003, Train: 0.2714, Val: 0.3640, Test: 0.4000\n",
            "Epoch: 004, Train: 0.4857, Val: 0.5060, Test: 0.5270\n",
            "Epoch: 005, Train: 0.5500, Val: 0.5540, Test: 0.5720\n",
            "Epoch: 006, Train: 0.6714, Val: 0.6760, Test: 0.6770\n",
            "Epoch: 007, Train: 0.7571, Val: 0.6620, Test: 0.6710\n",
            "Epoch: 008, Train: 0.7071, Val: 0.5380, Test: 0.5350\n",
            "Epoch: 009, Train: 0.5857, Val: 0.4080, Test: 0.4020\n",
            "Epoch: 010, Train: 0.5929, Val: 0.4100, Test: 0.4030\n",
            "Epoch: 011, Train: 0.6357, Val: 0.4380, Test: 0.4330\n",
            "Epoch: 012, Train: 0.6571, Val: 0.4420, Test: 0.4450\n",
            "Epoch: 013, Train: 0.7286, Val: 0.4800, Test: 0.4810\n",
            "Epoch: 014, Train: 0.8000, Val: 0.5360, Test: 0.5200\n",
            "Epoch: 015, Train: 0.8000, Val: 0.5580, Test: 0.5380\n",
            "Epoch: 016, Train: 0.8214, Val: 0.5900, Test: 0.5860\n",
            "Epoch: 017, Train: 0.8357, Val: 0.6140, Test: 0.6160\n",
            "Epoch: 018, Train: 0.8643, Val: 0.6360, Test: 0.6460\n",
            "Epoch: 019, Train: 0.8714, Val: 0.6140, Test: 0.6310\n",
            "Epoch: 020, Train: 0.8571, Val: 0.5860, Test: 0.5820\n",
            "Epoch: 021, Train: 0.8429, Val: 0.5640, Test: 0.5440\n",
            "Epoch: 022, Train: 0.8357, Val: 0.5600, Test: 0.5430\n",
            "Epoch: 023, Train: 0.8286, Val: 0.5560, Test: 0.5550\n",
            "Epoch: 024, Train: 0.8429, Val: 0.5780, Test: 0.5860\n",
            "Epoch: 025, Train: 0.8500, Val: 0.5940, Test: 0.6150\n",
            "Epoch: 026, Train: 0.8571, Val: 0.6040, Test: 0.6260\n",
            "Epoch: 027, Train: 0.8571, Val: 0.6220, Test: 0.6410\n",
            "Epoch: 028, Train: 0.9000, Val: 0.6420, Test: 0.6570\n",
            "Epoch: 029, Train: 0.9071, Val: 0.6540, Test: 0.6670\n",
            "Epoch: 030, Train: 0.9214, Val: 0.7140, Test: 0.7140\n",
            "Epoch: 031, Train: 0.9286, Val: 0.7340, Test: 0.7420\n",
            "Epoch: 032, Train: 0.9286, Val: 0.7600, Test: 0.7710\n",
            "Epoch: 033, Train: 0.9500, Val: 0.7660, Test: 0.7860\n",
            "Epoch: 034, Train: 0.9500, Val: 0.7780, Test: 0.7990\n",
            "Epoch: 035, Train: 0.9429, Val: 0.7920, Test: 0.8160\n",
            "Epoch: 036, Train: 0.9643, Val: 0.7920, Test: 0.8130\n",
            "Epoch: 037, Train: 0.9714, Val: 0.7900, Test: 0.8110\n",
            "Epoch: 038, Train: 0.9571, Val: 0.7840, Test: 0.8170\n",
            "Epoch: 039, Train: 0.9500, Val: 0.7880, Test: 0.8130\n",
            "Epoch: 040, Train: 0.9429, Val: 0.7860, Test: 0.8100\n",
            "Epoch: 041, Train: 0.9500, Val: 0.7860, Test: 0.8080\n",
            "Epoch: 042, Train: 0.9500, Val: 0.7900, Test: 0.8150\n",
            "Epoch: 043, Train: 0.9500, Val: 0.7960, Test: 0.8270\n",
            "Epoch: 044, Train: 0.9571, Val: 0.8040, Test: 0.8320\n",
            "Epoch: 045, Train: 0.9571, Val: 0.8060, Test: 0.8350\n",
            "Epoch: 046, Train: 0.9500, Val: 0.8100, Test: 0.8300\n",
            "Epoch: 047, Train: 0.9500, Val: 0.8040, Test: 0.8170\n",
            "Epoch: 048, Train: 0.9500, Val: 0.7880, Test: 0.8030\n",
            "Epoch: 049, Train: 0.9429, Val: 0.7820, Test: 0.7930\n",
            "Epoch: 050, Train: 0.9429, Val: 0.7720, Test: 0.7810\n",
            "Epoch: 051, Train: 0.9357, Val: 0.7780, Test: 0.7780\n",
            "Epoch: 052, Train: 0.9357, Val: 0.7660, Test: 0.7730\n",
            "Epoch: 053, Train: 0.9429, Val: 0.7720, Test: 0.7740\n",
            "Epoch: 054, Train: 0.9571, Val: 0.7720, Test: 0.7690\n",
            "Epoch: 055, Train: 0.9571, Val: 0.7760, Test: 0.7670\n",
            "Epoch: 056, Train: 0.9571, Val: 0.7740, Test: 0.7750\n",
            "Epoch: 057, Train: 0.9643, Val: 0.7820, Test: 0.7830\n",
            "Epoch: 058, Train: 0.9571, Val: 0.7900, Test: 0.7870\n",
            "Epoch: 059, Train: 0.9571, Val: 0.7900, Test: 0.7910\n",
            "Epoch: 060, Train: 0.9643, Val: 0.8020, Test: 0.8020\n",
            "Epoch: 061, Train: 0.9643, Val: 0.8100, Test: 0.8170\n",
            "Epoch: 062, Train: 0.9643, Val: 0.8060, Test: 0.8260\n",
            "Epoch: 063, Train: 0.9643, Val: 0.8080, Test: 0.8260\n",
            "Epoch: 064, Train: 0.9643, Val: 0.8080, Test: 0.8320\n",
            "Epoch: 065, Train: 0.9643, Val: 0.8080, Test: 0.8320\n",
            "Epoch: 066, Train: 0.9643, Val: 0.8080, Test: 0.8370\n",
            "Epoch: 067, Train: 0.9571, Val: 0.8040, Test: 0.8330\n",
            "Epoch: 068, Train: 0.9643, Val: 0.8040, Test: 0.8220\n",
            "Epoch: 069, Train: 0.9714, Val: 0.8080, Test: 0.8160\n",
            "Epoch: 070, Train: 0.9643, Val: 0.8060, Test: 0.8120\n",
            "Epoch: 071, Train: 0.9643, Val: 0.8060, Test: 0.7980\n",
            "Epoch: 072, Train: 0.9643, Val: 0.8020, Test: 0.8010\n",
            "Epoch: 073, Train: 0.9714, Val: 0.8020, Test: 0.8020\n",
            "Epoch: 074, Train: 0.9714, Val: 0.8080, Test: 0.8050\n",
            "Epoch: 075, Train: 0.9714, Val: 0.8080, Test: 0.8110\n",
            "Epoch: 076, Train: 0.9714, Val: 0.8100, Test: 0.8190\n",
            "Epoch: 077, Train: 0.9714, Val: 0.8120, Test: 0.8120\n",
            "Epoch: 078, Train: 0.9714, Val: 0.8020, Test: 0.8110\n",
            "Epoch: 079, Train: 0.9714, Val: 0.8000, Test: 0.8070\n",
            "Epoch: 080, Train: 0.9714, Val: 0.7960, Test: 0.8070\n",
            "Epoch: 081, Train: 0.9643, Val: 0.8020, Test: 0.8130\n",
            "Epoch: 082, Train: 0.9714, Val: 0.8040, Test: 0.8200\n",
            "Epoch: 083, Train: 0.9714, Val: 0.8040, Test: 0.8170\n",
            "Epoch: 084, Train: 0.9714, Val: 0.7980, Test: 0.8210\n",
            "Epoch: 085, Train: 0.9714, Val: 0.8040, Test: 0.8230\n",
            "Epoch: 086, Train: 0.9714, Val: 0.8080, Test: 0.8240\n",
            "Epoch: 087, Train: 0.9786, Val: 0.8060, Test: 0.8250\n",
            "Epoch: 088, Train: 0.9786, Val: 0.8080, Test: 0.8190\n",
            "Epoch: 089, Train: 0.9786, Val: 0.8080, Test: 0.8160\n",
            "Epoch: 090, Train: 0.9714, Val: 0.8120, Test: 0.8150\n",
            "Epoch: 091, Train: 0.9786, Val: 0.8080, Test: 0.8170\n",
            "Epoch: 092, Train: 0.9786, Val: 0.8100, Test: 0.8220\n",
            "Epoch: 093, Train: 0.9786, Val: 0.8080, Test: 0.8240\n",
            "Epoch: 094, Train: 0.9786, Val: 0.8140, Test: 0.8300\n",
            "Epoch: 095, Train: 0.9857, Val: 0.8100, Test: 0.8330\n",
            "Epoch: 096, Train: 0.9857, Val: 0.8080, Test: 0.8340\n",
            "Epoch: 097, Train: 0.9857, Val: 0.7980, Test: 0.8310\n",
            "Epoch: 098, Train: 0.9857, Val: 0.7960, Test: 0.8240\n",
            "Epoch: 099, Train: 0.9857, Val: 0.7920, Test: 0.8170\n",
            "Epoch: 100, Train: 0.9857, Val: 0.7960, Test: 0.8130\n",
            "Epoch: 101, Train: 0.9857, Val: 0.8000, Test: 0.8120\n",
            "Epoch: 102, Train: 0.9857, Val: 0.8060, Test: 0.8160\n",
            "Epoch: 103, Train: 0.9929, Val: 0.8000, Test: 0.8180\n",
            "Epoch: 104, Train: 0.9929, Val: 0.8020, Test: 0.8210\n",
            "Epoch: 105, Train: 0.9929, Val: 0.8060, Test: 0.8290\n",
            "Epoch: 106, Train: 0.9929, Val: 0.8060, Test: 0.8270\n",
            "Epoch: 107, Train: 0.9857, Val: 0.8100, Test: 0.8350\n",
            "Epoch: 108, Train: 0.9857, Val: 0.8100, Test: 0.8280\n",
            "Epoch: 109, Train: 0.9857, Val: 0.8060, Test: 0.8280\n",
            "Epoch: 110, Train: 0.9857, Val: 0.8020, Test: 0.8310\n",
            "Epoch: 111, Train: 0.9786, Val: 0.8040, Test: 0.8330\n",
            "Epoch: 112, Train: 0.9786, Val: 0.8080, Test: 0.8350\n",
            "Epoch: 113, Train: 0.9857, Val: 0.8180, Test: 0.8420\n",
            "Epoch: 114, Train: 0.9857, Val: 0.8220, Test: 0.8430\n",
            "Epoch: 115, Train: 0.9857, Val: 0.8240, Test: 0.8440\n",
            "Epoch: 116, Train: 0.9857, Val: 0.8260, Test: 0.8450\n",
            "Epoch: 117, Train: 0.9857, Val: 0.8140, Test: 0.8440\n",
            "Epoch: 118, Train: 0.9857, Val: 0.8100, Test: 0.8370\n",
            "Epoch: 119, Train: 0.9857, Val: 0.8140, Test: 0.8380\n",
            "Epoch: 120, Train: 0.9857, Val: 0.8160, Test: 0.8390\n",
            "Epoch: 121, Train: 0.9929, Val: 0.8120, Test: 0.8380\n",
            "Epoch: 122, Train: 0.9929, Val: 0.8120, Test: 0.8370\n",
            "Epoch: 123, Train: 0.9929, Val: 0.8120, Test: 0.8370\n",
            "Epoch: 124, Train: 0.9929, Val: 0.8120, Test: 0.8390\n",
            "Epoch: 125, Train: 0.9929, Val: 0.8080, Test: 0.8370\n",
            "Epoch: 126, Train: 0.9929, Val: 0.8040, Test: 0.8370\n",
            "Epoch: 127, Train: 0.9929, Val: 0.8020, Test: 0.8340\n",
            "Epoch: 128, Train: 0.9929, Val: 0.8080, Test: 0.8370\n",
            "Epoch: 129, Train: 0.9929, Val: 0.8080, Test: 0.8320\n",
            "Epoch: 130, Train: 0.9929, Val: 0.8080, Test: 0.8270\n",
            "Epoch: 131, Train: 0.9929, Val: 0.8100, Test: 0.8260\n",
            "Epoch: 132, Train: 0.9929, Val: 0.8100, Test: 0.8250\n",
            "Epoch: 133, Train: 0.9929, Val: 0.8080, Test: 0.8260\n",
            "Epoch: 134, Train: 0.9929, Val: 0.8020, Test: 0.8270\n",
            "Epoch: 135, Train: 0.9929, Val: 0.8060, Test: 0.8250\n",
            "Epoch: 136, Train: 0.9929, Val: 0.8040, Test: 0.8250\n",
            "Epoch: 137, Train: 0.9929, Val: 0.8000, Test: 0.8270\n",
            "Epoch: 138, Train: 0.9929, Val: 0.8020, Test: 0.8270\n",
            "Epoch: 139, Train: 0.9857, Val: 0.8000, Test: 0.8260\n",
            "Epoch: 140, Train: 0.9857, Val: 0.7980, Test: 0.8320\n",
            "Epoch: 141, Train: 0.9857, Val: 0.7960, Test: 0.8360\n",
            "Epoch: 142, Train: 0.9857, Val: 0.8000, Test: 0.8350\n",
            "Epoch: 143, Train: 0.9857, Val: 0.7980, Test: 0.8280\n",
            "Epoch: 144, Train: 0.9857, Val: 0.8000, Test: 0.8290\n",
            "Epoch: 145, Train: 0.9857, Val: 0.8020, Test: 0.8290\n",
            "Epoch: 146, Train: 0.9857, Val: 0.8020, Test: 0.8250\n",
            "Epoch: 147, Train: 0.9857, Val: 0.8000, Test: 0.8240\n",
            "Epoch: 148, Train: 0.9857, Val: 0.8000, Test: 0.8260\n",
            "Epoch: 149, Train: 0.9857, Val: 0.7960, Test: 0.8340\n",
            "Epoch: 150, Train: 0.9857, Val: 0.8040, Test: 0.8310\n",
            "Epoch: 151, Train: 0.9857, Val: 0.7980, Test: 0.8320\n",
            "Epoch: 152, Train: 0.9929, Val: 0.7980, Test: 0.8320\n",
            "Epoch: 153, Train: 0.9929, Val: 0.8000, Test: 0.8310\n",
            "Epoch: 154, Train: 0.9929, Val: 0.7980, Test: 0.8280\n",
            "Epoch: 155, Train: 0.9929, Val: 0.8000, Test: 0.8280\n",
            "Epoch: 156, Train: 0.9929, Val: 0.8020, Test: 0.8290\n",
            "Epoch: 157, Train: 0.9929, Val: 0.8020, Test: 0.8310\n",
            "Epoch: 158, Train: 0.9929, Val: 0.7980, Test: 0.8290\n",
            "Epoch: 159, Train: 0.9929, Val: 0.7960, Test: 0.8270\n",
            "Epoch: 160, Train: 0.9929, Val: 0.8000, Test: 0.8270\n",
            "Epoch: 161, Train: 0.9929, Val: 0.8000, Test: 0.8290\n",
            "Epoch: 162, Train: 0.9929, Val: 0.7980, Test: 0.8290\n",
            "Epoch: 163, Train: 0.9929, Val: 0.7980, Test: 0.8250\n",
            "Epoch: 164, Train: 0.9929, Val: 0.7960, Test: 0.8250\n",
            "Epoch: 165, Train: 0.9929, Val: 0.7980, Test: 0.8280\n",
            "Epoch: 166, Train: 0.9929, Val: 0.7960, Test: 0.8310\n",
            "Epoch: 167, Train: 0.9857, Val: 0.7920, Test: 0.8320\n",
            "Epoch: 168, Train: 0.9857, Val: 0.7960, Test: 0.8300\n",
            "Epoch: 169, Train: 0.9857, Val: 0.7980, Test: 0.8270\n",
            "Epoch: 170, Train: 0.9857, Val: 0.7960, Test: 0.8280\n",
            "Epoch: 171, Train: 0.9929, Val: 0.7980, Test: 0.8280\n",
            "Epoch: 172, Train: 0.9929, Val: 0.8000, Test: 0.8320\n",
            "Epoch: 173, Train: 0.9929, Val: 0.8000, Test: 0.8300\n",
            "Epoch: 174, Train: 0.9929, Val: 0.8000, Test: 0.8270\n",
            "Epoch: 175, Train: 0.9929, Val: 0.8000, Test: 0.8310\n",
            "Epoch: 176, Train: 0.9929, Val: 0.8000, Test: 0.8320\n",
            "Epoch: 177, Train: 0.9929, Val: 0.8020, Test: 0.8320\n",
            "Epoch: 178, Train: 0.9929, Val: 0.8020, Test: 0.8300\n",
            "Epoch: 179, Train: 0.9929, Val: 0.8020, Test: 0.8370\n",
            "Epoch: 180, Train: 0.9929, Val: 0.8020, Test: 0.8360\n",
            "Epoch: 181, Train: 0.9929, Val: 0.8000, Test: 0.8330\n",
            "Epoch: 182, Train: 0.9929, Val: 0.8000, Test: 0.8340\n",
            "Epoch: 183, Train: 0.9929, Val: 0.8040, Test: 0.8310\n",
            "Epoch: 184, Train: 0.9929, Val: 0.8020, Test: 0.8280\n",
            "Epoch: 185, Train: 0.9929, Val: 0.8020, Test: 0.8220\n",
            "Epoch: 186, Train: 0.9929, Val: 0.8040, Test: 0.8220\n",
            "Epoch: 187, Train: 0.9929, Val: 0.8020, Test: 0.8200\n",
            "Epoch: 188, Train: 0.9929, Val: 0.7980, Test: 0.8200\n",
            "Epoch: 189, Train: 0.9929, Val: 0.8000, Test: 0.8230\n",
            "Epoch: 190, Train: 0.9929, Val: 0.8020, Test: 0.8210\n",
            "Epoch: 191, Train: 0.9929, Val: 0.7960, Test: 0.8200\n",
            "Epoch: 192, Train: 0.9929, Val: 0.8040, Test: 0.8230\n",
            "Epoch: 193, Train: 0.9929, Val: 0.8100, Test: 0.8200\n",
            "Epoch: 194, Train: 0.9929, Val: 0.8080, Test: 0.8260\n",
            "Epoch: 195, Train: 0.9929, Val: 0.8100, Test: 0.8280\n",
            "Epoch: 196, Train: 0.9929, Val: 0.8120, Test: 0.8300\n",
            "Epoch: 197, Train: 0.9929, Val: 0.8160, Test: 0.8330\n",
            "Epoch: 198, Train: 0.9929, Val: 0.8160, Test: 0.8320\n",
            "Epoch: 199, Train: 0.9857, Val: 0.8120, Test: 0.8350\n",
            "Epoch: 200, Train: 0.9857, Val: 0.8040, Test: 0.8340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, headsIn):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GATv2Conv(in_channels, 8, heads=headsIn, dropout=0.6)\n",
        "        self.conv2 = GATv2Conv(headsIn * 8, out_channels, heads=1, concat=False,\n",
        "                             dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    out, accs = model(data.x, data.edge_index), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        acc = float((out[mask].argmax(-1) == data.y[mask]).sum() / mask.sum())\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "test_accuracies = []\n",
        "train_accuracies = []\n",
        "for i in range(1, 21):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model = Net(dataset.num_features, dataset.num_classes, i).to(device)\n",
        "  data = data.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "  for epoch in range(1, 201):\n",
        "    train(data)\n",
        "    train_acc, val_acc, test_acc = test(data)\n",
        "    #print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, 'f'Test: {test_acc:.4f}')\n",
        "    if epoch == 200:\n",
        "      test_accuracies.append(test_acc)\n",
        "      train_accuracies.append(train_acc)\n",
        "plt.plot(range(1,21), test_accuracies, 'r--', range(1,21), train_accuracies, 'g^')\n",
        "plt.xlabel('Number of Heads')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['test accuracy', 'train accuracy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "xl9XKSwVODQx",
        "outputId": "65b21f08-a449-4875-cada-fd602df1c338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Citeseer Dataset\n",
        "dataset = 'Citeseer'\n",
        "dataset = Planetoid(root='/tmp/Citeseer', name=dataset, transform=T.NormalizeFeatures())\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "tFpWWof2OG7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c93dce-01da-4759-ab13-28dfab681cad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GATv2Conv(in_channels, 8, heads=8, dropout=0.6)\n",
        "        self.conv2 = GATv2Conv(8 * 8, out_channels, heads=1, concat=False,\n",
        "                             dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net(dataset.num_features, dataset.num_classes).to(device)\n",
        "data = data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "def train(data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    out, accs = model(data.x, data.edge_index), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        acc = float((out[mask].argmax(-1) == data.y[mask]).sum() / mask.sum())\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    train(data)\n",
        "    train_acc, val_acc, test_acc = test(data)\n",
        "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
        "          f'Test: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-04KykSgOKQR",
        "outputId": "7195a8a5-1572-4ce9-de7f-4fcd6ceaa086"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train: 0.3000, Val: 0.2760, Test: 0.2740\n",
            "Epoch: 002, Train: 0.1833, Val: 0.1400, Test: 0.1600\n",
            "Epoch: 003, Train: 0.1750, Val: 0.1380, Test: 0.1600\n",
            "Epoch: 004, Train: 0.1750, Val: 0.1420, Test: 0.1610\n",
            "Epoch: 005, Train: 0.2750, Val: 0.1820, Test: 0.1920\n",
            "Epoch: 006, Train: 0.4250, Val: 0.2540, Test: 0.2880\n",
            "Epoch: 007, Train: 0.3750, Val: 0.2940, Test: 0.2980\n",
            "Epoch: 008, Train: 0.2917, Val: 0.1900, Test: 0.2090\n",
            "Epoch: 009, Train: 0.2083, Val: 0.1740, Test: 0.1830\n",
            "Epoch: 010, Train: 0.1917, Val: 0.1720, Test: 0.1830\n",
            "Epoch: 011, Train: 0.1917, Val: 0.1740, Test: 0.1820\n",
            "Epoch: 012, Train: 0.2417, Val: 0.1780, Test: 0.1840\n",
            "Epoch: 013, Train: 0.3167, Val: 0.1900, Test: 0.2010\n",
            "Epoch: 014, Train: 0.4000, Val: 0.2220, Test: 0.2340\n",
            "Epoch: 015, Train: 0.5250, Val: 0.3360, Test: 0.3640\n",
            "Epoch: 016, Train: 0.6750, Val: 0.4240, Test: 0.4580\n",
            "Epoch: 017, Train: 0.8000, Val: 0.3940, Test: 0.4440\n",
            "Epoch: 018, Train: 0.8500, Val: 0.3880, Test: 0.4390\n",
            "Epoch: 019, Train: 0.8500, Val: 0.4120, Test: 0.4450\n",
            "Epoch: 020, Train: 0.8750, Val: 0.5100, Test: 0.4980\n",
            "Epoch: 021, Train: 0.8917, Val: 0.5800, Test: 0.5630\n",
            "Epoch: 022, Train: 0.8833, Val: 0.6260, Test: 0.6090\n",
            "Epoch: 023, Train: 0.8333, Val: 0.6160, Test: 0.6170\n",
            "Epoch: 024, Train: 0.8250, Val: 0.6060, Test: 0.6180\n",
            "Epoch: 025, Train: 0.8083, Val: 0.6000, Test: 0.6000\n",
            "Epoch: 026, Train: 0.8000, Val: 0.5940, Test: 0.5880\n",
            "Epoch: 027, Train: 0.8000, Val: 0.5980, Test: 0.5950\n",
            "Epoch: 028, Train: 0.8167, Val: 0.5920, Test: 0.5990\n",
            "Epoch: 029, Train: 0.8250, Val: 0.6060, Test: 0.6140\n",
            "Epoch: 030, Train: 0.8583, Val: 0.6200, Test: 0.6250\n",
            "Epoch: 031, Train: 0.9250, Val: 0.6280, Test: 0.6460\n",
            "Epoch: 032, Train: 0.9167, Val: 0.6360, Test: 0.6480\n",
            "Epoch: 033, Train: 0.9333, Val: 0.6560, Test: 0.6480\n",
            "Epoch: 034, Train: 0.9333, Val: 0.6700, Test: 0.6470\n",
            "Epoch: 035, Train: 0.9250, Val: 0.6540, Test: 0.6530\n",
            "Epoch: 036, Train: 0.9167, Val: 0.6700, Test: 0.6600\n",
            "Epoch: 037, Train: 0.9167, Val: 0.6740, Test: 0.6630\n",
            "Epoch: 038, Train: 0.9083, Val: 0.6860, Test: 0.6780\n",
            "Epoch: 039, Train: 0.9083, Val: 0.6880, Test: 0.6830\n",
            "Epoch: 040, Train: 0.9083, Val: 0.6880, Test: 0.6830\n",
            "Epoch: 041, Train: 0.9167, Val: 0.6960, Test: 0.6850\n",
            "Epoch: 042, Train: 0.9167, Val: 0.6980, Test: 0.6920\n",
            "Epoch: 043, Train: 0.9167, Val: 0.7040, Test: 0.6840\n",
            "Epoch: 044, Train: 0.9167, Val: 0.7060, Test: 0.6870\n",
            "Epoch: 045, Train: 0.9250, Val: 0.6980, Test: 0.6940\n",
            "Epoch: 046, Train: 0.9333, Val: 0.6840, Test: 0.6860\n",
            "Epoch: 047, Train: 0.9333, Val: 0.6800, Test: 0.6860\n",
            "Epoch: 048, Train: 0.9250, Val: 0.6780, Test: 0.6800\n",
            "Epoch: 049, Train: 0.9250, Val: 0.6780, Test: 0.6830\n",
            "Epoch: 050, Train: 0.9250, Val: 0.6780, Test: 0.6880\n",
            "Epoch: 051, Train: 0.9250, Val: 0.6880, Test: 0.6940\n",
            "Epoch: 052, Train: 0.9250, Val: 0.6860, Test: 0.7020\n",
            "Epoch: 053, Train: 0.9333, Val: 0.7020, Test: 0.7080\n",
            "Epoch: 054, Train: 0.9250, Val: 0.7060, Test: 0.7140\n",
            "Epoch: 055, Train: 0.9250, Val: 0.7120, Test: 0.7100\n",
            "Epoch: 056, Train: 0.9250, Val: 0.7060, Test: 0.7120\n",
            "Epoch: 057, Train: 0.9167, Val: 0.7000, Test: 0.7050\n",
            "Epoch: 058, Train: 0.9250, Val: 0.7080, Test: 0.7050\n",
            "Epoch: 059, Train: 0.9250, Val: 0.6960, Test: 0.6930\n",
            "Epoch: 060, Train: 0.9333, Val: 0.6880, Test: 0.6910\n",
            "Epoch: 061, Train: 0.9333, Val: 0.6860, Test: 0.6850\n",
            "Epoch: 062, Train: 0.9333, Val: 0.6820, Test: 0.6780\n",
            "Epoch: 063, Train: 0.9333, Val: 0.6780, Test: 0.6700\n",
            "Epoch: 064, Train: 0.9250, Val: 0.6920, Test: 0.6700\n",
            "Epoch: 065, Train: 0.9167, Val: 0.6960, Test: 0.6740\n",
            "Epoch: 066, Train: 0.9083, Val: 0.6980, Test: 0.6760\n",
            "Epoch: 067, Train: 0.9167, Val: 0.6940, Test: 0.6750\n",
            "Epoch: 068, Train: 0.9167, Val: 0.6960, Test: 0.6820\n",
            "Epoch: 069, Train: 0.9250, Val: 0.6980, Test: 0.6740\n",
            "Epoch: 070, Train: 0.9250, Val: 0.7060, Test: 0.6800\n",
            "Epoch: 071, Train: 0.9167, Val: 0.7040, Test: 0.6810\n",
            "Epoch: 072, Train: 0.9167, Val: 0.7020, Test: 0.6810\n",
            "Epoch: 073, Train: 0.9250, Val: 0.7020, Test: 0.6830\n",
            "Epoch: 074, Train: 0.9250, Val: 0.7000, Test: 0.6880\n",
            "Epoch: 075, Train: 0.9250, Val: 0.6960, Test: 0.6920\n",
            "Epoch: 076, Train: 0.9333, Val: 0.7020, Test: 0.6960\n",
            "Epoch: 077, Train: 0.9333, Val: 0.6960, Test: 0.6980\n",
            "Epoch: 078, Train: 0.9333, Val: 0.6880, Test: 0.6980\n",
            "Epoch: 079, Train: 0.9333, Val: 0.6840, Test: 0.6890\n",
            "Epoch: 080, Train: 0.9333, Val: 0.6900, Test: 0.6880\n",
            "Epoch: 081, Train: 0.9333, Val: 0.6960, Test: 0.6940\n",
            "Epoch: 082, Train: 0.9333, Val: 0.7000, Test: 0.6890\n",
            "Epoch: 083, Train: 0.9500, Val: 0.6920, Test: 0.6770\n",
            "Epoch: 084, Train: 0.9500, Val: 0.6820, Test: 0.6700\n",
            "Epoch: 085, Train: 0.9417, Val: 0.6840, Test: 0.6690\n",
            "Epoch: 086, Train: 0.9417, Val: 0.6860, Test: 0.6710\n",
            "Epoch: 087, Train: 0.9500, Val: 0.6860, Test: 0.6800\n",
            "Epoch: 088, Train: 0.9500, Val: 0.6920, Test: 0.6840\n",
            "Epoch: 089, Train: 0.9417, Val: 0.6900, Test: 0.6900\n",
            "Epoch: 090, Train: 0.9583, Val: 0.6960, Test: 0.6880\n",
            "Epoch: 091, Train: 0.9500, Val: 0.6960, Test: 0.6920\n",
            "Epoch: 092, Train: 0.9417, Val: 0.7000, Test: 0.6940\n",
            "Epoch: 093, Train: 0.9417, Val: 0.7040, Test: 0.7000\n",
            "Epoch: 094, Train: 0.9417, Val: 0.6940, Test: 0.7020\n",
            "Epoch: 095, Train: 0.9417, Val: 0.7000, Test: 0.6970\n",
            "Epoch: 096, Train: 0.9417, Val: 0.6840, Test: 0.6940\n",
            "Epoch: 097, Train: 0.9417, Val: 0.6860, Test: 0.6910\n",
            "Epoch: 098, Train: 0.9333, Val: 0.6940, Test: 0.6920\n",
            "Epoch: 099, Train: 0.9333, Val: 0.6960, Test: 0.6870\n",
            "Epoch: 100, Train: 0.9333, Val: 0.7040, Test: 0.6920\n",
            "Epoch: 101, Train: 0.9333, Val: 0.7020, Test: 0.6940\n",
            "Epoch: 102, Train: 0.9333, Val: 0.7020, Test: 0.6960\n",
            "Epoch: 103, Train: 0.9333, Val: 0.7080, Test: 0.6960\n",
            "Epoch: 104, Train: 0.9333, Val: 0.7020, Test: 0.6940\n",
            "Epoch: 105, Train: 0.9417, Val: 0.6960, Test: 0.6830\n",
            "Epoch: 106, Train: 0.9417, Val: 0.6880, Test: 0.6800\n",
            "Epoch: 107, Train: 0.9500, Val: 0.6780, Test: 0.6760\n",
            "Epoch: 108, Train: 0.9583, Val: 0.6800, Test: 0.6760\n",
            "Epoch: 109, Train: 0.9500, Val: 0.6820, Test: 0.6760\n",
            "Epoch: 110, Train: 0.9500, Val: 0.6940, Test: 0.6820\n",
            "Epoch: 111, Train: 0.9500, Val: 0.6980, Test: 0.6850\n",
            "Epoch: 112, Train: 0.9500, Val: 0.6920, Test: 0.6830\n",
            "Epoch: 113, Train: 0.9500, Val: 0.6920, Test: 0.6820\n",
            "Epoch: 114, Train: 0.9417, Val: 0.6920, Test: 0.6820\n",
            "Epoch: 115, Train: 0.9500, Val: 0.6920, Test: 0.6830\n",
            "Epoch: 116, Train: 0.9500, Val: 0.6900, Test: 0.6840\n",
            "Epoch: 117, Train: 0.9500, Val: 0.6900, Test: 0.6830\n",
            "Epoch: 118, Train: 0.9500, Val: 0.6860, Test: 0.6830\n",
            "Epoch: 119, Train: 0.9417, Val: 0.6940, Test: 0.6800\n",
            "Epoch: 120, Train: 0.9333, Val: 0.6940, Test: 0.6850\n",
            "Epoch: 121, Train: 0.9333, Val: 0.7020, Test: 0.6850\n",
            "Epoch: 122, Train: 0.9333, Val: 0.7000, Test: 0.6880\n",
            "Epoch: 123, Train: 0.9500, Val: 0.7000, Test: 0.6920\n",
            "Epoch: 124, Train: 0.9500, Val: 0.7060, Test: 0.6890\n",
            "Epoch: 125, Train: 0.9500, Val: 0.7020, Test: 0.6900\n",
            "Epoch: 126, Train: 0.9417, Val: 0.6940, Test: 0.6930\n",
            "Epoch: 127, Train: 0.9417, Val: 0.6940, Test: 0.6940\n",
            "Epoch: 128, Train: 0.9417, Val: 0.6960, Test: 0.6970\n",
            "Epoch: 129, Train: 0.9417, Val: 0.6940, Test: 0.7020\n",
            "Epoch: 130, Train: 0.9417, Val: 0.6940, Test: 0.7000\n",
            "Epoch: 131, Train: 0.9417, Val: 0.6980, Test: 0.6930\n",
            "Epoch: 132, Train: 0.9583, Val: 0.7000, Test: 0.6870\n",
            "Epoch: 133, Train: 0.9583, Val: 0.7100, Test: 0.6900\n",
            "Epoch: 134, Train: 0.9583, Val: 0.6980, Test: 0.6810\n",
            "Epoch: 135, Train: 0.9583, Val: 0.6940, Test: 0.6720\n",
            "Epoch: 136, Train: 0.9583, Val: 0.6840, Test: 0.6670\n",
            "Epoch: 137, Train: 0.9583, Val: 0.6860, Test: 0.6650\n",
            "Epoch: 138, Train: 0.9583, Val: 0.6900, Test: 0.6680\n",
            "Epoch: 139, Train: 0.9583, Val: 0.6920, Test: 0.6710\n",
            "Epoch: 140, Train: 0.9583, Val: 0.6920, Test: 0.6770\n",
            "Epoch: 141, Train: 0.9583, Val: 0.7040, Test: 0.6900\n",
            "Epoch: 142, Train: 0.9750, Val: 0.7080, Test: 0.7030\n",
            "Epoch: 143, Train: 0.9500, Val: 0.7120, Test: 0.7080\n",
            "Epoch: 144, Train: 0.9500, Val: 0.7100, Test: 0.7150\n",
            "Epoch: 145, Train: 0.9500, Val: 0.7040, Test: 0.7210\n",
            "Epoch: 146, Train: 0.9500, Val: 0.7040, Test: 0.7230\n",
            "Epoch: 147, Train: 0.9500, Val: 0.7040, Test: 0.7260\n",
            "Epoch: 148, Train: 0.9500, Val: 0.7040, Test: 0.7190\n",
            "Epoch: 149, Train: 0.9500, Val: 0.7100, Test: 0.7220\n",
            "Epoch: 150, Train: 0.9583, Val: 0.7100, Test: 0.7160\n",
            "Epoch: 151, Train: 0.9583, Val: 0.7160, Test: 0.7200\n",
            "Epoch: 152, Train: 0.9583, Val: 0.7100, Test: 0.7110\n",
            "Epoch: 153, Train: 0.9750, Val: 0.7040, Test: 0.7020\n",
            "Epoch: 154, Train: 0.9750, Val: 0.7160, Test: 0.6900\n",
            "Epoch: 155, Train: 0.9583, Val: 0.7080, Test: 0.6820\n",
            "Epoch: 156, Train: 0.9583, Val: 0.7000, Test: 0.6780\n",
            "Epoch: 157, Train: 0.9583, Val: 0.6980, Test: 0.6770\n",
            "Epoch: 158, Train: 0.9667, Val: 0.6860, Test: 0.6760\n",
            "Epoch: 159, Train: 0.9667, Val: 0.6780, Test: 0.6760\n",
            "Epoch: 160, Train: 0.9500, Val: 0.6840, Test: 0.6780\n",
            "Epoch: 161, Train: 0.9417, Val: 0.6900, Test: 0.6840\n",
            "Epoch: 162, Train: 0.9667, Val: 0.7000, Test: 0.6870\n",
            "Epoch: 163, Train: 0.9667, Val: 0.7040, Test: 0.6840\n",
            "Epoch: 164, Train: 0.9667, Val: 0.6980, Test: 0.6940\n",
            "Epoch: 165, Train: 0.9667, Val: 0.7000, Test: 0.7040\n",
            "Epoch: 166, Train: 0.9583, Val: 0.7000, Test: 0.7070\n",
            "Epoch: 167, Train: 0.9583, Val: 0.7000, Test: 0.7050\n",
            "Epoch: 168, Train: 0.9667, Val: 0.7060, Test: 0.7070\n",
            "Epoch: 169, Train: 0.9667, Val: 0.6980, Test: 0.7090\n",
            "Epoch: 170, Train: 0.9833, Val: 0.7080, Test: 0.7070\n",
            "Epoch: 171, Train: 0.9750, Val: 0.7100, Test: 0.7040\n",
            "Epoch: 172, Train: 0.9750, Val: 0.7000, Test: 0.6960\n",
            "Epoch: 173, Train: 0.9583, Val: 0.6900, Test: 0.6750\n",
            "Epoch: 174, Train: 0.9667, Val: 0.6880, Test: 0.6730\n",
            "Epoch: 175, Train: 0.9667, Val: 0.6880, Test: 0.6640\n",
            "Epoch: 176, Train: 0.9667, Val: 0.6760, Test: 0.6650\n",
            "Epoch: 177, Train: 0.9833, Val: 0.6820, Test: 0.6690\n",
            "Epoch: 178, Train: 0.9833, Val: 0.6820, Test: 0.6680\n",
            "Epoch: 179, Train: 0.9750, Val: 0.6880, Test: 0.6750\n",
            "Epoch: 180, Train: 0.9750, Val: 0.7080, Test: 0.6690\n",
            "Epoch: 181, Train: 0.9667, Val: 0.7040, Test: 0.6810\n",
            "Epoch: 182, Train: 0.9750, Val: 0.7140, Test: 0.6890\n",
            "Epoch: 183, Train: 0.9750, Val: 0.7100, Test: 0.6930\n",
            "Epoch: 184, Train: 0.9583, Val: 0.7120, Test: 0.6940\n",
            "Epoch: 185, Train: 0.9583, Val: 0.7140, Test: 0.7030\n",
            "Epoch: 186, Train: 0.9583, Val: 0.7180, Test: 0.7050\n",
            "Epoch: 187, Train: 0.9583, Val: 0.7120, Test: 0.7070\n",
            "Epoch: 188, Train: 0.9583, Val: 0.7120, Test: 0.7000\n",
            "Epoch: 189, Train: 0.9667, Val: 0.7100, Test: 0.7020\n",
            "Epoch: 190, Train: 0.9833, Val: 0.7080, Test: 0.6940\n",
            "Epoch: 191, Train: 0.9750, Val: 0.7080, Test: 0.6860\n",
            "Epoch: 192, Train: 0.9833, Val: 0.7000, Test: 0.6800\n",
            "Epoch: 193, Train: 0.9833, Val: 0.6860, Test: 0.6770\n",
            "Epoch: 194, Train: 0.9833, Val: 0.6860, Test: 0.6760\n",
            "Epoch: 195, Train: 0.9833, Val: 0.6840, Test: 0.6730\n",
            "Epoch: 196, Train: 0.9833, Val: 0.6820, Test: 0.6740\n",
            "Epoch: 197, Train: 0.9667, Val: 0.7080, Test: 0.6800\n",
            "Epoch: 198, Train: 0.9583, Val: 0.7180, Test: 0.6840\n",
            "Epoch: 199, Train: 0.9667, Val: 0.7160, Test: 0.6940\n",
            "Epoch: 200, Train: 0.9667, Val: 0.7120, Test: 0.6980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, headsIn):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GATv2Conv(in_channels, 8, heads=headsIn, dropout=0.6)\n",
        "        self.conv2 = GATv2Conv(headsIn * 8, out_channels, heads=1, concat=False,\n",
        "                             dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    out, accs = model(data.x, data.edge_index), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        acc = float((out[mask].argmax(-1) == data.y[mask]).sum() / mask.sum())\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "test_accuracies = []\n",
        "train_accuracies = []\n",
        "for i in range(1, 21):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model = Net(dataset.num_features, dataset.num_classes, i).to(device)\n",
        "  data = data.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.0005)\n",
        "  for epoch in range(1, 201):\n",
        "    train(data)\n",
        "    train_acc, val_acc, test_acc = test(data)\n",
        "    #print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, 'f'Test: {test_acc:.4f}')\n",
        "    if epoch == 200:\n",
        "      test_accuracies.append(test_acc)\n",
        "      train_accuracies.append(train_acc)\n",
        "plt.plot(range(1,21), test_accuracies, 'r--', range(1,21), train_accuracies, 'g^')\n",
        "plt.xlabel('Number of Heads')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['test accuracy', 'train accuracy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "XVFtrNjvOMds",
        "outputId": "ba6c330e-2c4b-49d2-cc4d-b8d2113f78fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pubmed Dataset\n",
        "dataset = 'Pubmed'\n",
        "dataset = Planetoid(root='/tmp/Pubmed', name = dataset, transform=T.NormalizeFeatures())\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "VD3FTqSZOOxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GATv2Conv(in_channels, 8, heads=8, dropout=0.6)\n",
        "        self.conv2 = GATv2Conv(8 * 8, out_channels, heads=8, concat=False,\n",
        "                             dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net(dataset.num_features, dataset.num_classes).to(device)\n",
        "data = data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
        "\n",
        "\n",
        "def train(data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    out, accs = model(data.x, data.edge_index), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        acc = float((out[mask].argmax(-1) == data.y[mask]).sum() / mask.sum())\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    train(data)\n",
        "    train_acc, val_acc, test_acc = test(data)\n",
        "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, '\n",
        "          f'Test: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfjCIwYMOQgz",
        "outputId": "fe900e25-4f25-43f0-899d-de3fdce74f77"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train: 0.3333, Val: 0.3880, Test: 0.4130\n",
            "Epoch: 002, Train: 0.3333, Val: 0.3880, Test: 0.4130\n",
            "Epoch: 003, Train: 0.4667, Val: 0.4200, Test: 0.4410\n",
            "Epoch: 004, Train: 0.4667, Val: 0.2680, Test: 0.2650\n",
            "Epoch: 005, Train: 0.5167, Val: 0.3420, Test: 0.3270\n",
            "Epoch: 006, Train: 0.6333, Val: 0.4760, Test: 0.4400\n",
            "Epoch: 007, Train: 0.6500, Val: 0.5500, Test: 0.5190\n",
            "Epoch: 008, Train: 0.6167, Val: 0.5480, Test: 0.5250\n",
            "Epoch: 009, Train: 0.6167, Val: 0.5320, Test: 0.5210\n",
            "Epoch: 010, Train: 0.6167, Val: 0.5320, Test: 0.5180\n",
            "Epoch: 011, Train: 0.6167, Val: 0.5320, Test: 0.5180\n",
            "Epoch: 012, Train: 0.6333, Val: 0.5440, Test: 0.5290\n",
            "Epoch: 013, Train: 0.7167, Val: 0.5600, Test: 0.5520\n",
            "Epoch: 014, Train: 0.8000, Val: 0.6200, Test: 0.6170\n",
            "Epoch: 015, Train: 0.8333, Val: 0.6600, Test: 0.6640\n",
            "Epoch: 016, Train: 0.8500, Val: 0.6940, Test: 0.6800\n",
            "Epoch: 017, Train: 0.9000, Val: 0.7120, Test: 0.6880\n",
            "Epoch: 018, Train: 0.9000, Val: 0.7380, Test: 0.7030\n",
            "Epoch: 019, Train: 0.9000, Val: 0.7420, Test: 0.7150\n",
            "Epoch: 020, Train: 0.9000, Val: 0.7380, Test: 0.7110\n",
            "Epoch: 021, Train: 0.8833, Val: 0.7300, Test: 0.6960\n",
            "Epoch: 022, Train: 0.8833, Val: 0.7300, Test: 0.6950\n",
            "Epoch: 023, Train: 0.9000, Val: 0.7340, Test: 0.7000\n",
            "Epoch: 024, Train: 0.8833, Val: 0.7440, Test: 0.7030\n",
            "Epoch: 025, Train: 0.9000, Val: 0.7560, Test: 0.7060\n",
            "Epoch: 026, Train: 0.9000, Val: 0.7500, Test: 0.7130\n",
            "Epoch: 027, Train: 0.9000, Val: 0.7480, Test: 0.7250\n",
            "Epoch: 028, Train: 0.9000, Val: 0.7480, Test: 0.7240\n",
            "Epoch: 029, Train: 0.9000, Val: 0.7520, Test: 0.7130\n",
            "Epoch: 030, Train: 0.9000, Val: 0.7440, Test: 0.7100\n",
            "Epoch: 031, Train: 0.9000, Val: 0.7520, Test: 0.7120\n",
            "Epoch: 032, Train: 0.9000, Val: 0.7440, Test: 0.7190\n",
            "Epoch: 033, Train: 0.9000, Val: 0.7360, Test: 0.7190\n",
            "Epoch: 034, Train: 0.9000, Val: 0.7400, Test: 0.7140\n",
            "Epoch: 035, Train: 0.9000, Val: 0.7380, Test: 0.7110\n",
            "Epoch: 036, Train: 0.9000, Val: 0.7340, Test: 0.7090\n",
            "Epoch: 037, Train: 0.9000, Val: 0.7420, Test: 0.7150\n",
            "Epoch: 038, Train: 0.9000, Val: 0.7460, Test: 0.7150\n",
            "Epoch: 039, Train: 0.9167, Val: 0.7480, Test: 0.7090\n",
            "Epoch: 040, Train: 0.9167, Val: 0.7500, Test: 0.7020\n",
            "Epoch: 041, Train: 0.9333, Val: 0.7400, Test: 0.7080\n",
            "Epoch: 042, Train: 0.9333, Val: 0.7360, Test: 0.7100\n",
            "Epoch: 043, Train: 0.9333, Val: 0.7340, Test: 0.7090\n",
            "Epoch: 044, Train: 0.9333, Val: 0.7380, Test: 0.7100\n",
            "Epoch: 045, Train: 0.9333, Val: 0.7340, Test: 0.7080\n",
            "Epoch: 046, Train: 0.9333, Val: 0.7420, Test: 0.7100\n",
            "Epoch: 047, Train: 0.9167, Val: 0.7480, Test: 0.7060\n",
            "Epoch: 048, Train: 0.9167, Val: 0.7520, Test: 0.7060\n",
            "Epoch: 049, Train: 0.9167, Val: 0.7480, Test: 0.7150\n",
            "Epoch: 050, Train: 0.9000, Val: 0.7380, Test: 0.7050\n",
            "Epoch: 051, Train: 0.9167, Val: 0.7380, Test: 0.7070\n",
            "Epoch: 052, Train: 0.9167, Val: 0.7380, Test: 0.7040\n",
            "Epoch: 053, Train: 0.9167, Val: 0.7340, Test: 0.7100\n",
            "Epoch: 054, Train: 0.9167, Val: 0.7360, Test: 0.7100\n",
            "Epoch: 055, Train: 0.9333, Val: 0.7360, Test: 0.7140\n",
            "Epoch: 056, Train: 0.9333, Val: 0.7500, Test: 0.7260\n",
            "Epoch: 057, Train: 0.9167, Val: 0.7580, Test: 0.7200\n",
            "Epoch: 058, Train: 0.9167, Val: 0.7580, Test: 0.7170\n",
            "Epoch: 059, Train: 0.9167, Val: 0.7580, Test: 0.7180\n",
            "Epoch: 060, Train: 0.9333, Val: 0.7560, Test: 0.7140\n",
            "Epoch: 061, Train: 0.9333, Val: 0.7620, Test: 0.7130\n",
            "Epoch: 062, Train: 0.9333, Val: 0.7580, Test: 0.7170\n",
            "Epoch: 063, Train: 0.9167, Val: 0.7660, Test: 0.7160\n",
            "Epoch: 064, Train: 0.9167, Val: 0.7640, Test: 0.7210\n",
            "Epoch: 065, Train: 0.9167, Val: 0.7640, Test: 0.7250\n",
            "Epoch: 066, Train: 0.9333, Val: 0.7580, Test: 0.7270\n",
            "Epoch: 067, Train: 0.9333, Val: 0.7620, Test: 0.7270\n",
            "Epoch: 068, Train: 0.9333, Val: 0.7620, Test: 0.7320\n",
            "Epoch: 069, Train: 0.9333, Val: 0.7620, Test: 0.7330\n",
            "Epoch: 070, Train: 0.9333, Val: 0.7660, Test: 0.7340\n",
            "Epoch: 071, Train: 0.9333, Val: 0.7680, Test: 0.7350\n",
            "Epoch: 072, Train: 0.9167, Val: 0.7680, Test: 0.7320\n",
            "Epoch: 073, Train: 0.9167, Val: 0.7660, Test: 0.7320\n",
            "Epoch: 074, Train: 0.9167, Val: 0.7660, Test: 0.7280\n",
            "Epoch: 075, Train: 0.9167, Val: 0.7660, Test: 0.7290\n",
            "Epoch: 076, Train: 0.9167, Val: 0.7700, Test: 0.7310\n",
            "Epoch: 077, Train: 0.9333, Val: 0.7680, Test: 0.7340\n",
            "Epoch: 078, Train: 0.9333, Val: 0.7680, Test: 0.7360\n",
            "Epoch: 079, Train: 0.9333, Val: 0.7700, Test: 0.7360\n",
            "Epoch: 080, Train: 0.9333, Val: 0.7680, Test: 0.7410\n",
            "Epoch: 081, Train: 0.9333, Val: 0.7700, Test: 0.7460\n",
            "Epoch: 082, Train: 0.9333, Val: 0.7720, Test: 0.7520\n",
            "Epoch: 083, Train: 0.9333, Val: 0.7760, Test: 0.7500\n",
            "Epoch: 084, Train: 0.9333, Val: 0.7780, Test: 0.7500\n",
            "Epoch: 085, Train: 0.9333, Val: 0.7740, Test: 0.7510\n",
            "Epoch: 086, Train: 0.9333, Val: 0.7740, Test: 0.7520\n",
            "Epoch: 087, Train: 0.9333, Val: 0.7740, Test: 0.7520\n",
            "Epoch: 088, Train: 0.9333, Val: 0.7740, Test: 0.7530\n",
            "Epoch: 089, Train: 0.9333, Val: 0.7780, Test: 0.7550\n",
            "Epoch: 090, Train: 0.9333, Val: 0.7820, Test: 0.7550\n",
            "Epoch: 091, Train: 0.9333, Val: 0.7800, Test: 0.7570\n",
            "Epoch: 092, Train: 0.9333, Val: 0.7820, Test: 0.7590\n",
            "Epoch: 093, Train: 0.9333, Val: 0.7860, Test: 0.7580\n",
            "Epoch: 094, Train: 0.9333, Val: 0.7820, Test: 0.7570\n",
            "Epoch: 095, Train: 0.9333, Val: 0.7840, Test: 0.7620\n",
            "Epoch: 096, Train: 0.9333, Val: 0.7840, Test: 0.7560\n",
            "Epoch: 097, Train: 0.9333, Val: 0.7860, Test: 0.7540\n",
            "Epoch: 098, Train: 0.9333, Val: 0.7880, Test: 0.7560\n",
            "Epoch: 099, Train: 0.9333, Val: 0.7860, Test: 0.7580\n",
            "Epoch: 100, Train: 0.9333, Val: 0.7860, Test: 0.7560\n",
            "Epoch: 101, Train: 0.9333, Val: 0.7860, Test: 0.7600\n",
            "Epoch: 102, Train: 0.9500, Val: 0.7900, Test: 0.7610\n",
            "Epoch: 103, Train: 0.9333, Val: 0.7960, Test: 0.7660\n",
            "Epoch: 104, Train: 0.9333, Val: 0.7920, Test: 0.7660\n",
            "Epoch: 105, Train: 0.9333, Val: 0.7940, Test: 0.7660\n",
            "Epoch: 106, Train: 0.9333, Val: 0.7960, Test: 0.7650\n",
            "Epoch: 107, Train: 0.9333, Val: 0.8040, Test: 0.7640\n",
            "Epoch: 108, Train: 0.9500, Val: 0.7980, Test: 0.7670\n",
            "Epoch: 109, Train: 0.9500, Val: 0.7900, Test: 0.7680\n",
            "Epoch: 110, Train: 0.9500, Val: 0.7960, Test: 0.7680\n",
            "Epoch: 111, Train: 0.9500, Val: 0.7980, Test: 0.7650\n",
            "Epoch: 112, Train: 0.9500, Val: 0.8020, Test: 0.7640\n",
            "Epoch: 113, Train: 0.9500, Val: 0.8020, Test: 0.7680\n",
            "Epoch: 114, Train: 0.9500, Val: 0.7940, Test: 0.7700\n",
            "Epoch: 115, Train: 0.9500, Val: 0.7860, Test: 0.7740\n",
            "Epoch: 116, Train: 0.9500, Val: 0.7880, Test: 0.7750\n",
            "Epoch: 117, Train: 0.9500, Val: 0.7860, Test: 0.7750\n",
            "Epoch: 118, Train: 0.9500, Val: 0.7900, Test: 0.7670\n",
            "Epoch: 119, Train: 0.9667, Val: 0.7940, Test: 0.7620\n",
            "Epoch: 120, Train: 0.9667, Val: 0.7940, Test: 0.7580\n",
            "Epoch: 121, Train: 0.9667, Val: 0.7920, Test: 0.7470\n",
            "Epoch: 122, Train: 0.9667, Val: 0.7920, Test: 0.7550\n",
            "Epoch: 123, Train: 0.9667, Val: 0.7960, Test: 0.7640\n",
            "Epoch: 124, Train: 0.9667, Val: 0.7940, Test: 0.7670\n",
            "Epoch: 125, Train: 0.9500, Val: 0.7940, Test: 0.7750\n",
            "Epoch: 126, Train: 0.9500, Val: 0.7940, Test: 0.7800\n",
            "Epoch: 127, Train: 0.9500, Val: 0.7840, Test: 0.7820\n",
            "Epoch: 128, Train: 0.9500, Val: 0.7840, Test: 0.7900\n",
            "Epoch: 129, Train: 0.9667, Val: 0.7940, Test: 0.7850\n",
            "Epoch: 130, Train: 0.9667, Val: 0.7940, Test: 0.7790\n",
            "Epoch: 131, Train: 0.9667, Val: 0.8060, Test: 0.7760\n",
            "Epoch: 132, Train: 0.9667, Val: 0.8060, Test: 0.7770\n",
            "Epoch: 133, Train: 0.9667, Val: 0.8040, Test: 0.7690\n",
            "Epoch: 134, Train: 0.9667, Val: 0.7960, Test: 0.7650\n",
            "Epoch: 135, Train: 0.9667, Val: 0.7960, Test: 0.7660\n",
            "Epoch: 136, Train: 0.9667, Val: 0.8020, Test: 0.7660\n",
            "Epoch: 137, Train: 0.9667, Val: 0.8040, Test: 0.7750\n",
            "Epoch: 138, Train: 0.9667, Val: 0.8080, Test: 0.7760\n",
            "Epoch: 139, Train: 0.9667, Val: 0.8040, Test: 0.7800\n",
            "Epoch: 140, Train: 0.9667, Val: 0.7980, Test: 0.7790\n",
            "Epoch: 141, Train: 0.9667, Val: 0.7980, Test: 0.7810\n",
            "Epoch: 142, Train: 0.9667, Val: 0.7980, Test: 0.7780\n",
            "Epoch: 143, Train: 0.9667, Val: 0.7960, Test: 0.7790\n",
            "Epoch: 144, Train: 0.9667, Val: 0.7960, Test: 0.7790\n",
            "Epoch: 145, Train: 0.9667, Val: 0.8040, Test: 0.7750\n",
            "Epoch: 146, Train: 0.9667, Val: 0.8020, Test: 0.7760\n",
            "Epoch: 147, Train: 0.9667, Val: 0.8020, Test: 0.7770\n",
            "Epoch: 148, Train: 0.9667, Val: 0.7960, Test: 0.7790\n",
            "Epoch: 149, Train: 0.9667, Val: 0.7940, Test: 0.7810\n",
            "Epoch: 150, Train: 0.9667, Val: 0.7980, Test: 0.7840\n",
            "Epoch: 151, Train: 0.9667, Val: 0.7960, Test: 0.7850\n",
            "Epoch: 152, Train: 0.9667, Val: 0.7940, Test: 0.7860\n",
            "Epoch: 153, Train: 0.9667, Val: 0.7960, Test: 0.7860\n",
            "Epoch: 154, Train: 0.9667, Val: 0.7960, Test: 0.7830\n",
            "Epoch: 155, Train: 0.9667, Val: 0.8000, Test: 0.7820\n",
            "Epoch: 156, Train: 0.9667, Val: 0.7960, Test: 0.7820\n",
            "Epoch: 157, Train: 0.9667, Val: 0.8020, Test: 0.7750\n",
            "Epoch: 158, Train: 0.9667, Val: 0.8040, Test: 0.7750\n",
            "Epoch: 159, Train: 0.9667, Val: 0.8040, Test: 0.7720\n",
            "Epoch: 160, Train: 0.9667, Val: 0.8080, Test: 0.7730\n",
            "Epoch: 161, Train: 0.9667, Val: 0.8020, Test: 0.7770\n",
            "Epoch: 162, Train: 0.9667, Val: 0.7980, Test: 0.7830\n",
            "Epoch: 163, Train: 0.9667, Val: 0.8020, Test: 0.7840\n",
            "Epoch: 164, Train: 0.9667, Val: 0.8040, Test: 0.7790\n",
            "Epoch: 165, Train: 0.9667, Val: 0.8060, Test: 0.7790\n",
            "Epoch: 166, Train: 0.9667, Val: 0.8060, Test: 0.7790\n",
            "Epoch: 167, Train: 0.9667, Val: 0.8040, Test: 0.7800\n",
            "Epoch: 168, Train: 0.9667, Val: 0.8020, Test: 0.7850\n",
            "Epoch: 169, Train: 0.9667, Val: 0.8020, Test: 0.7840\n",
            "Epoch: 170, Train: 0.9667, Val: 0.8060, Test: 0.7830\n",
            "Epoch: 171, Train: 0.9667, Val: 0.7980, Test: 0.7820\n",
            "Epoch: 172, Train: 0.9667, Val: 0.7980, Test: 0.7810\n",
            "Epoch: 173, Train: 0.9667, Val: 0.8020, Test: 0.7810\n",
            "Epoch: 174, Train: 0.9667, Val: 0.8040, Test: 0.7830\n",
            "Epoch: 175, Train: 0.9667, Val: 0.8000, Test: 0.7860\n",
            "Epoch: 176, Train: 0.9667, Val: 0.8040, Test: 0.7840\n",
            "Epoch: 177, Train: 0.9667, Val: 0.8060, Test: 0.7840\n",
            "Epoch: 178, Train: 0.9667, Val: 0.8020, Test: 0.7820\n",
            "Epoch: 179, Train: 0.9667, Val: 0.8060, Test: 0.7810\n",
            "Epoch: 180, Train: 0.9667, Val: 0.8040, Test: 0.7810\n",
            "Epoch: 181, Train: 0.9667, Val: 0.8020, Test: 0.7890\n",
            "Epoch: 182, Train: 0.9667, Val: 0.7940, Test: 0.7890\n",
            "Epoch: 183, Train: 0.9667, Val: 0.7940, Test: 0.7890\n",
            "Epoch: 184, Train: 0.9667, Val: 0.7980, Test: 0.7860\n",
            "Epoch: 185, Train: 0.9667, Val: 0.8020, Test: 0.7840\n",
            "Epoch: 186, Train: 0.9667, Val: 0.8040, Test: 0.7820\n",
            "Epoch: 187, Train: 0.9667, Val: 0.8060, Test: 0.7710\n",
            "Epoch: 188, Train: 0.9667, Val: 0.8040, Test: 0.7690\n",
            "Epoch: 189, Train: 0.9667, Val: 0.8060, Test: 0.7690\n",
            "Epoch: 190, Train: 0.9667, Val: 0.8020, Test: 0.7760\n",
            "Epoch: 191, Train: 0.9667, Val: 0.8000, Test: 0.7800\n",
            "Epoch: 192, Train: 0.9833, Val: 0.7980, Test: 0.7850\n",
            "Epoch: 193, Train: 0.9833, Val: 0.7980, Test: 0.7870\n",
            "Epoch: 194, Train: 0.9833, Val: 0.7960, Test: 0.7860\n",
            "Epoch: 195, Train: 0.9833, Val: 0.7920, Test: 0.7860\n",
            "Epoch: 196, Train: 0.9833, Val: 0.8020, Test: 0.7880\n",
            "Epoch: 197, Train: 0.9667, Val: 0.8060, Test: 0.7860\n",
            "Epoch: 198, Train: 0.9667, Val: 0.8020, Test: 0.7830\n",
            "Epoch: 199, Train: 0.9667, Val: 0.8080, Test: 0.7810\n",
            "Epoch: 200, Train: 0.9667, Val: 0.8140, Test: 0.7720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, headsIn):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = GATv2Conv(in_channels, 8, heads=headsIn, dropout=0.6)\n",
        "        self.conv2 = GATv2Conv(headsIn * 8, out_channels, heads=8, concat=False,\n",
        "                             dropout=0.6)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = F.elu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    out, accs = model(data.x, data.edge_index), []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        acc = float((out[mask].argmax(-1) == data.y[mask]).sum() / mask.sum())\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "\n",
        "test_accuracies = []\n",
        "train_accuracies = []\n",
        "for i in range(1, 21):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model = Net(dataset.num_features, dataset.num_classes, i).to(device)\n",
        "  data = data.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
        "  for epoch in range(1, 201):\n",
        "    train(data)\n",
        "    train_acc, val_acc, test_acc = test(data)\n",
        "    #print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, Val: {val_acc:.4f}, 'f'Test: {test_acc:.4f}')\n",
        "    if epoch == 200:\n",
        "      test_accuracies.append(test_acc)\n",
        "      train_accuracies.append(train_acc)\n",
        "plt.plot(range(1,21), test_accuracies, 'r--', range(1,21), train_accuracies, 'g^')\n",
        "plt.xlabel('Number of Heads')*8855\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['test accuracy', 'train accuracy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "isFdtRQjOU-n",
        "outputId": "f12845bf-6253-40cd-d129-66a9ce352c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}